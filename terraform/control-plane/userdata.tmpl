#!/usr/bin/env bash

set -ex

## Setting variables
AWS_DEFAULT_REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone 2>/dev/null | head -c -1)
AWS_AVAILABILITY_ZONE=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)
AWS_ACCOUNT_ID=$(curl -s http://169.254.169.254/latest/meta-data/identity-credentials/ec2/info | grep AccountId | awk '{print $3}' | tr -d '"')
LOCAL_IPV4=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)
LOCAL_HOSTNAME=$(curl -s http://169.254.169.254/latest/meta-data/local-hostname)
INSTANCE_TYPE=$(curl -s http://169.254.169.254/latest/meta-data/instance-type)

## Using the pre-baked rebel-fox-kubernetes AMI

## Creating the /etc/kubernetes/pki path for writing the ca certs stored in ssm to.
mkdir -p /etc/kubernetes/pki/etcd

## Grabbing Pre-generated CA certs and Bootstrap token from ssm parameter store
## Bash has a cool substring replacement mechanism builtin to manipulate variables.
## The file output uses this mechanism as such {the variable/pattern to match/value that replaces the pattern match}

## kuberetes ca
for p in $(aws ssm get-parameters-by-path --path /${tmpl_k8s_cluster_id}/ | jq -r .Parameters[].Name)
do
    aws ssm get-parameter --name $${p} --with-decryption | jq -r .Parameter.Value > "$${p/${tmpl_k8s_cluster_id}/etc/kubernetes/pki}"
done

## etcd ca
for p in $(aws ssm get-parameters-by-path --path /${tmpl_k8s_cluster_id}/etcd | jq -r .Parameters[].Name)
do
    aws ssm get-parameter --name $${p} --with-decryption | jq -r .Parameter.Value > "$${p/${tmpl_k8s_cluster_id}/etc/kubernetes/pki}"
done

## Fetching and mounting the persistent etcd data volume
ebs-bootstrap \
-aws-region $${AWS_DEFAULT_REGION} \
-ebs-volume-name ${tmpl_k8s_cluster_id}-etcd-${tmpl_member_count}-data \
-block-device /dev/xvde -filesystem-type ext4 \
-mount-point /var/lib/etcd

echo "/dev/xvde /var/lib/etcd ext4 defaults,nofail 0 2" >> /etc/fstab

## creating the kubeadm init config
cat <<EOF > /etc/kubernetes/kubeadm-init.config
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: $${LOCAL_IPV4}
  bindPort: 6443

bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: $(cat /etc/kubernetes/pki/bootstrap.token)
  ttl: "0"
  usages:
  - signing
  - authentication

nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: $${LOCAL_HOSTNAME}
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master

---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
clusterName: ${tmpl_k8s_cluster_id}
imageRepository: k8s.gcr.io
kubernetesVersion: v${tmpl_kubernetes_version}
controlPlaneEndpoint: ${tmpl_external_api}
networking:
  dnsDomain: cluster.local
  serviceSubnet: ${tmpl_service_cidr}
  podSubnet: ${tmpl_pod_cidr}
apiServer:
  certSANs:
  - ${tmpl_external_api}
  - ${tmpl_internal_api}
  - $${LOCAL_HOSTNAME}
  - $${LOCAL_IPV4}
EOF

cat <<EOF > /etc/kubernetes/kubeadm-control-plane-join.config
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: JoinConfiguration
discovery:
  bootstrapToken:
    apiServerEndpoint: ${tmpl_external_api}:6443
    token: $(cat /etc/kubernetes/pki/bootstrap.token)
    unsafeSkipCAVerification: true
  timeout: 5m0s
  tlsBootstrapToken: $(cat /etc/kubernetes/pki/bootstrap.token)
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: $${LOCAL_HOSTNAME}
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
  kubeletExtraArgs:
    cloud-provider: external
    node-labels: "kubernetes.io/hostname=$${LOCAL_HOSTNAME},node.kubernetes.io/instance-type=$${INSTANCE_TYPE},topology.kubernetes.io/region=$${AWS_DEFAULT_REGION},topology.kubernetes.io/zone=$${AWS_AVAILABILITY_ZONE}"
controlPlane:
  localAPIEndpoint:
    advertiseAddress: $${LOCAL_IPV4}
    bindPort: 6443
EOF

if [[ "${tmpl_member}" == "01" ]]; then
    echo "Prime control-plane node: running init config"
    kubeadm init --config /etc/kubernetes/kubeadm-init.config \
    --ignore-preflight-errors=DirAvailable--var-lib-etcd
else
    echo "Replica control-plane node: running join config"
    kubeadm join --config /etc/kubernetes/kubeadm-control-plane-join.config \
    --ignore-preflight-errors=DirAvailable--var-lib-etcd
fi

set -x ## allowing script to continue even if non-zero is returned
## removing the taint from the control-plane nodes
kubectl --kubeconfig /etc/kubernetes/admin.conf taint nodes \
--all node-role.kubernetes.io/master-

## install
kubectl --kubeconfig /etc/kubernetes/admin.conf create \
-f https://docs.projectcalico.org/manifests/calico.yaml


set -ex
## copying admin config to root and ec2-user .kube directories
## using a while loop w/ timeout command to recover from a possible race condition
mkdir -p /home/ec2-user/.kube
mkdir -p /root/.kube
while timeout -k 70 60 cp /etc/kubernetes/admin.conf /home/ec2-user/.kube && cp /etc/kubernetes/admin.conf /root/.kube; [ $? = 124 ]
do sleep 2  # Pause before retry
done
